{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sR3-TcoQVrDK"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timezone\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"YOUTUBE_API_KEY\"] = \"YOUR KEY\" # Add your key here\n",
        "API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
        "CHANNEL_ID = \"UCldfgbzNILYZA4dmDt4Cd6A\" # Secular Talk\n",
        "BASE = \"https://www.googleapis.com/youtube/v3\""
      ],
      "metadata": {
        "id": "uR3jSZatWMH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Get uploads playlist ID\n",
        "resp = requests.get(\n",
        "    f\"{BASE}/channels\",\n",
        "    params={\"part\": \"contentDetails\", \"id\": CHANNEL_ID, \"key\": API_KEY},\n",
        ").json()\n",
        "\n",
        "uploads_playlist = resp[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]"
      ],
      "metadata": {
        "id": "y0fLhP9UWaAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Category lookup (US)\n",
        "cats = requests.get(\n",
        "    f\"{BASE}/videoCategories\",\n",
        "    params={\"part\": \"snippet\", \"regionCode\": \"US\", \"key\": API_KEY},\n",
        ").json()\n",
        "\n",
        "category_map = {c[\"id\"]: c[\"snippet\"][\"title\"] for c in cats[\"items\"]}"
      ],
      "metadata": {
        "id": "ZpI1UGKTWf0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Collect 2015 video IDs\n",
        "cutoff = datetime(2015, 1, 1, tzinfo=timezone.utc)\n",
        "video_ids = []\n",
        "page_token = None\n",
        "\n",
        "while True:\n",
        "    params = {\n",
        "        \"part\": \"contentDetails\",\n",
        "        \"playlistId\": uploads_playlist,\n",
        "        \"maxResults\": 50,\n",
        "        \"key\": API_KEY,\n",
        "    }\n",
        "    if page_token:\n",
        "        params[\"pageToken\"] = page_token\n",
        "\n",
        "    data = requests.get(f\"{BASE}/playlistItems\", params=params).json()\n",
        "\n",
        "    for item in data[\"items\"]:\n",
        "        pub = item[\"contentDetails\"][\"videoPublishedAt\"]\n",
        "        pub_dt = datetime.fromisoformat(pub.replace(\"Z\", \"+00:00\"))\n",
        "        if pub_dt < cutoff:\n",
        "            page_token = None\n",
        "            break\n",
        "        video_ids.append(item[\"contentDetails\"][\"videoId\"])\n",
        "\n",
        "    page_token = data.get(\"nextPageToken\")\n",
        "    if not page_token:\n",
        "        break"
      ],
      "metadata": {
        "id": "4oRGfHCsWhum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Fetch video details (batch of 50)\n",
        "rows = []\n",
        "\n",
        "for i in range(0, len(video_ids), 50):\n",
        "    chunk = \",\".join(video_ids[i:i+50])\n",
        "    vids = requests.get(\n",
        "        f\"{BASE}/videos\",\n",
        "        params={\n",
        "            \"part\": \"snippet,statistics,contentDetails\",\n",
        "            \"id\": chunk,\n",
        "            \"key\": API_KEY,\n",
        "        },\n",
        "    ).json()\n",
        "\n",
        "    for v in vids[\"items\"]:\n",
        "        sn = v[\"snippet\"]\n",
        "        st = v.get(\"statistics\", {})\n",
        "        cd = v[\"contentDetails\"]\n",
        "        cid = sn.get(\"categoryId\")\n",
        "\n",
        "        rows.append({\n",
        "            \"videoId\": v[\"id\"],\n",
        "            \"title\": sn[\"title\"],\n",
        "            \"description\": sn[\"description\"],\n",
        "            \"tags\": sn.get(\"tags\"),\n",
        "            \"publishedAt\": sn[\"publishedAt\"],\n",
        "            \"duration\": cd[\"duration\"],\n",
        "            \"category\": category_map.get(cid),\n",
        "            \"viewCount\": int(st[\"viewCount\"]) if \"viewCount\" in st else None,\n",
        "            \"likeCount\": int(st[\"likeCount\"]) if \"likeCount\" in st else None,\n",
        "            \"commentCount\": int(st[\"commentCount\"]) if \"commentCount\" in st else None,\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"publishedAt\", ascending=False)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QrephNfBWn7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean date column\n",
        "df['publishedAt'] = pd.to_datetime(df['publishedAt'])"
      ],
      "metadata": {
        "id": "bq8mCd-FWwWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# explore data structure\n",
        "df.info()"
      ],
      "metadata": {
        "id": "fnvqvbfZW3Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate csv file\n",
        "df.to_csv(\"data.csv\", index=False)"
      ],
      "metadata": {
        "id": "1CwERrMpWok3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}